{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick start guide\n",
    "\n",
    "This notebook details the minimal steps needed to train a particle detection model and then use that model to extract predicted particle coordinates with Topaz. For a more detailed walkthrough with visualization of outputs from the different steps, please see: https://github.com/tbepler/topaz/blob/master/tutorial/02_walkthrough.ipynb\n",
    "\n",
    "__Topaz is assumed to be installed in a conda environment named \"topaz\" for purposes of running topaz commands within bash cells.__ If topaz was installed in some other way, then the \"source activate topaz\" lines will need to be removed or changed below. See https://github.com/tbepler/topaz#installation for details on installing Topaz.\n",
    "\n",
    "### Demo dataset\n",
    "\n",
    "This guide uses a demo dataset that can be downloaded [here](http://bergerlab-downloads.csail.mit.edu/topaz/topaz-tutorial-data.tar.gz) and should be unpacked directly in this (the tutorial) directory.\n",
    "\n",
    "```\n",
    "wget http://bergerlab-downloads.csail.mit.edu/topaz/topaz-tutorial-data.tar.gz\n",
    "tar -xzvf topaz-tutorial-data.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Topaz pipeline\n",
    "\n",
    "The Topaz particle picking pipeline proceeds as follows:\n",
    "\n",
    "(Before running Topaz): label a small (100-1000, more is likely to give better results) number of particles on your micrographs using the software of your choice.\n",
    "\n",
    "1. (Preprocessing) Micrographs are downsampled and normalized, any labeled particle coordinates also need to be scaled appropriately\n",
    "2. (Training) The particle detection model is trained on the preprocessed micrographs using the labeled particle coordinates. This requires setting the expected number of particles per micrograph.\n",
    "3. (Extraction) Using the trained model, particle coordinates and their associated scores are extracted from the micrographs. This requires knowing the particle radius in pixels on the downsampled micrographs.\n",
    "\n",
    "(Optional postprocessing): examine classifier performance, rescale particle coordinates, extract particle stack, change particle file format, filter particles by model score, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this guide\n",
    "\n",
    "We assume that the user already has a file containing their labeled particle coordinates (data/EMPIAR-10025/rawdata/particles.txt in this case), that the expected number of particles per micrograph is 300, and that the particle radius on the processed micrographs is 7 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing\n",
    "\n",
    "Downsample the micrographs by a factor of 16 and also scale the labeled coordinates to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "source activate topaz\n",
    "\n",
    "# we'll store the processed data in data/EMPIAR-10025/processed\n",
    "# so we need to make these directories first\n",
    "mkdir -p data/EMPIAR-10025/processed\n",
    "mkdir -p data/EMPIAR-10025/processed/micrographs\n",
    "\n",
    "# to run the preprocess command, we pass the input micrographs as command line arguments\n",
    "# preprocess will write the processed images to the directory specified with the -o argument\n",
    "# -s sets the downsampling amount (in this case, we downsample by a factor of 16)\n",
    "topaz preprocess -s 16 -o data/EMPIAR-10025/processed/micrographs/ data/EMPIAR-10025/rawdata/micrographs/*.mrc\n",
    "\n",
    "# this command takes the particle coordinates matched to the original micrographs\n",
    "# and scales them by 1/16 (-s is downscaling)\n",
    "# the -x option applies upscaling instead\n",
    "topaz convert -s 16 -o data/EMPIAR-10025/processed/particles.txt data/EMPIAR-10025/rawdata/particles.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model training\n",
    "\n",
    "Given the preprocessed micrographs and particle coordinates, we train the particle detection model using positive-unlabeled learning. This requires us to specify the expected number of particles per micrograph, which is 300 in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Loading model: resnet8\n",
      "# Model parameters: units=32, dropout=0.0, bn=on\n",
      "# Receptive field: 71\n",
      "# Using device=0 with cuda=True\n",
      "# Loaded 30 training micrographs with 1500 labeled particles\n",
      "# source\tsplit\tp_observed\tnum_positive_regions\ttotal_regions\n",
      "# 0\ttrain\t0.00654\t43500\t6652800\n",
      "# Specified expected number of particle per micrograph = 300.0\n",
      "# With radius = 3\n",
      "# Setting pi = 0.03923160173160173\n",
      "# minibatch_size=256, epoch_size=5000, num_epochs=10\n",
      "/data/cb/tbepler/workspace/topaz/topaz/methods.py:127: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  q_discrete = F.softmax(q_discrete) # dim=0 doesn't work for pytorch=0.2.0\n",
      "# Done!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source activate topaz\n",
    "\n",
    "# first, make sure we have the folders where we want to put the saved models\n",
    "# store the saved models in saved_models/EMPIAR-10025\n",
    "mkdir -p saved_models\n",
    "mkdir -p saved_models/EMPIAR-10025\n",
    "\n",
    "# Now, we train the model\n",
    "# We set -n 300 to tell Topaz that we expect there to be on average 300 particles per micrograph\n",
    "# and --num-workers=8 to speed up training\n",
    "# the models will be saved to the saved_models/EMPIAR-10025 directory\n",
    "topaz train -n 300 \\\n",
    "            --num-workers=8 \\\n",
    "            --train-images data/EMPIAR-10025/processed/micrographs/ \\\n",
    "            --train-targets data/EMPIAR-10025/processed/particles.txt \\\n",
    "            --save-prefix=saved_models/EMPIAR-10025/model \\\n",
    "            -o saved_models/EMPIAR-10025/model_training.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extract particle coordinates\n",
    "\n",
    "Now that we have a trained model, we use it to extract predicted particle coordinates using a particle radius of 7 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "source activate topaz\n",
    "\n",
    "## make a directory to write the topaz particles to\n",
    "mkdir -p data/EMPIAR-10025/topaz\n",
    "\n",
    "## extract particle coordinates using the  trained model\n",
    "## we set the radius parameter to 7 (-r 7)\n",
    "## to prevent extracting particle coordinates closer than the radius of the particle\n",
    "## i.e. we don't want multiple predictions for a single particle\n",
    "## we also set -x 16 in order to scale the coordinates back to the original micrograph size\n",
    "\n",
    "topaz extract -r 7 -x 16 -m saved_models/EMPIAR-10025/model_epoch10.sav \\\n",
    "              -o data/EMPIAR-10025/topaz/predicted_particles_all_upsampled.txt \\\n",
    "              data/EMPIAR-10025/processed/micrographs/*.mrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# (Optional) change format of particle coordinates file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "source activate topaz\n",
    "\n",
    "# we can convert the particles file to .star format (and others) by changing the file extension\n",
    "# of the output file (data/EMPIAR-10025/topaz/predicted_particles_all_upsampled.txt)\n",
    "# to .star (data/EMPIAR-10025/topaz/predicted_particles_all_upsampled.star)\n",
    "# the convert command can also filter the particle table by model score using the -t argument\n",
    "# e.g. -t 0 would only keep particles with scores >= 0\n",
    "\n",
    "topaz convert -o data/EMPIAR-10025/topaz/predicted_particles_all_upsampled.star \\\n",
    "              data/EMPIAR-10025/topaz/predicted_particles_all_upsampled.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's it!\n",
    "\n",
    "We now have a table containing particle coordinates for each micrograph with their corresponding model score."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:topaz]",
   "language": "python",
   "name": "conda-env-topaz-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
